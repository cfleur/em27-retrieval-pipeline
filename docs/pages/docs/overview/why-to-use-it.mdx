---
title: Why to use this pipeline?
---

import Image from 'next/image';

# Why this pipeline?

## How do we use it?

Due to operating MUCCnet we retrieve a lot of EM27/SUN data and have used this pipeline since early 2022 (release date of Proffast 2.0). The image below are the daily mean values of the averaged total column concentrations of CO2 of our EM27/SUN located in Munich central.

<Image
    src='/images/202204261158_ma_tum_long_term_data_yield.png'
    alt='long term data yield of one MUCCnet station'
    width={2400}
    height={1500}
    className='my-8'
/>

## Why does this pipeline exist?

KIT already provides a tool to dispatch Proffast retrieval jobs, the Proffast Pylot. This pipeline wraps around the Pylot and uses it to interact with Proffast. It should not replace the Pylot but extend its capabilities in an opt-in style. You can build your own logic using the Pylot directly, or you can benefit from our bullet-proofing of running it for a lot of data.

The pipeline consists of three building blocks that are required to retrieve EM27 data:

| Task                                                                                      | Script Entrypoint                   |
| ----------------------------------------------------------------------------------------- | ----------------------------------- |
| 1. Downloading vertical profiles from the Caltech FTP server                              | `src/download_vertical_profiles.py` |
| 2. Running the Proffast Pylot to generate the averaged column concentrations              | `src/run_automated_proffast.py`     |
| 3. Postprocessing the individual station outputs and merging them into daily output files | `src/merge_retrieval_outputs.py`    |

The data flow from input to merged outputs:

<Image
    src='/images/revised-retrieval-pipeline-architecture.png'
    alt='long term data yield of one MUCCnet station'
    width={2400}
    height={1500}
    className='my-8 max-w-lg mx-auto'
/>

The Pylot codebase only provides the second part. In addition to tasks one and three, the pipeline offers:

-   **Easy configuration of using a validated `config.json` and `manual-queue.json`:** By "validated", we mean that before the processing starts, the config files content will be parsed and validated against a JSON schema. This way, you can be sure that the pipeline will not fail due to a misconfiguration, and you will immediately get precise error messages.
-   **Opinionated management of station metadata:** We manage our EM27 metadata using JSON files instead of database tables, which has several benefits mentioned in the metadata repository https://github.com/tum-esm/em27-metadata
-   **Filtering of interferogram files that Proffast cannot process:** With the plain Pylot, Proffast will fail for whole days of data even when only a few out of thousands of interferograms are corrupted. The pipeline will filter out these interferograms and only pass the valid ones to Proffast. This filtering functionality can be used standalone using our utility library: https://tum-esm.github.io/utils/#/api-reference/interferograms
-   **Parallelization of the Proffast Pylot execution:** The Pylot already provides a parallelization. Still, the outputs of multiple days are merged into one output directory, and the Pylot can only process data from one station at a time. The pipeline will run the Pylot execution for each station and date individually inside a containerized environment and run a configurable number of containers in parallel.
-   **Write-protection of all input files during the execution of the container:** The bigger the codebase that uses a file, the hard it is to verify that the input file is not modified during the execution; this is especially true for low-level code like Fortran. The pipeline will duplicate the datalogger files and the vertical profiles. Since there can be more than 10 Gb of interferograms per container, copying these is not that performance; hence we use symlinks to rename the files in a format the Pylot expects, and the permissions of the original files will be set to read-only during a container's execution (and restored afterwards).
-   **Comprehensive logs and output data management:** It will store failed and succeeded containers. The output is the same as with the Pylot but also contains all config files the pipeline used to run this container and logs generated by the container.
-   **Merging of smoothed individual station outputs into daily output files:** This uses a Savitzky-Golay filter from the `SciPy` library with a windows size of 31 and a polygon order of 3. The output files contain header sections with everything needed to reproduce the output file based on the raw interferograms. See [Merged Outputs Files ðŸ‘‡](#merged-outputs-files) for more details.
-   **Documentation and complete API reference:** hosted at https://tum-esm.github.io/automated-retrieval-pipeline/
